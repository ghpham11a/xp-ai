{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a4486e-5a55-4e5e-a2c1-c362882b4777",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-tools-tavily-research python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b3f21e-1b0f-4ccf-8913-7bd12fbd8c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "# so everything with LlamaIndex works correctly in a notebook\n",
    "import nest_asyncio\n",
    "import os\n",
    "\n",
    "nest_asyncio.apply()\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7df53f92-aa6a-4f5d-a7d1-e2dca90d843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### CREATE TOOLS #####\n",
    "from llama_index.tools.tavily_research import TavilyToolSpec\n",
    "\n",
    "tavily_tool = TavilyToolSpec(api_key=os.getenv(\"TAVILY_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4992870-2392-48bc-9bd4-94e07b1ebc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INITIALISE LLM #####\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14051ec4-fec3-4efa-b652-328611eb65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INITIALISE AGENT #####\n",
    "from llama_index.core.agent.workflow import AgentWorkflow\n",
    "\n",
    "workflow = AgentWorkflow.from_tools_or_functions(\n",
    "    tavily_tool.to_tool_list(),\n",
    "    llm=llm,\n",
    "    system_prompt=\"You're a helpful assistant that can search the web for information\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcc05b85-4d69-4872-abfa-d5ef45afabdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current weather in San Francisco is as follows:\n",
      "\n",
      "- **Temperature**: 12.8째C (55째F)\n",
      "- **Condition**: Partly cloudy\n",
      "- **Wind**: 11.4 mph (18.4 kph) from the WNW\n",
      "- **Humidity**: 74%\n",
      "- **Visibility**: 16 km (9 miles)\n",
      "- **Pressure**: 1021 mb (30.16 in)\n",
      "- **Feels Like**: 11.1째C (51.9째F)\n",
      "\n",
      "The weather is currently mild, and it is nighttime in San Francisco. You can expect similar conditions throughout the evening. \n",
      "\n",
      "For more detailed information, you can check [WeatherAPI](https://www.weatherapi.com/)."
     ]
    }
   ],
   "source": [
    "##### ASK A QUESTION WITH STREAMING #####\n",
    "from llama_index.core.agent.workflow import AgentStream\n",
    "\n",
    "handler = workflow.run(user_msg=\"What's the weather like in San Francisco?\")\n",
    "\n",
    "async for event in handler.stream_events():\n",
    "    if isinstance(event, AgentStream):\n",
    "        print(event.delta, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
