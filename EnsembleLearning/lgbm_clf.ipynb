{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85eb17af-be17-4247-be19-54dcd5e3f9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy lightgbm scikit-learn matplotlib --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8580ed9c-a6c5-4c75-a774-adb497b468d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    TimeSeriesSplit,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    GroupKFold,\n",
    "    StratifiedGroupKFold,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4266ec87-1ac9-4179-9643-6caf6f95fa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\antho\\AppData\\Local\\Temp\\ipykernel_18476\\1015928117.py:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data[\"ever_married\"].replace(\"Yes\", True).replace(\"No\", False)\n"
     ]
    }
   ],
   "source": [
    "def get_prep_data():\n",
    "    data = pd.read_csv(\n",
    "        \"./data/healthcare-dataset-stroke-data.csv\"\n",
    "    )\n",
    "    data[\"ever_married\"] = (\n",
    "        data[\"ever_married\"].replace(\"Yes\", True).replace(\"No\", False)\n",
    "    )\n",
    "    data[\"gender\"] = data[\"gender\"].astype(\"category\")\n",
    "    data[\"smoking_status\"] = data[\"smoking_status\"].astype(\"category\")\n",
    "    data[\"Residence_type\"] = data[\"Residence_type\"].astype(\"category\")\n",
    "    data[\"work_type\"] = data[\"work_type\"].astype(\"category\")\n",
    "    data[\"doctor\"] = np.random.randint(0, 8, size=len(data))\n",
    "    holdout_ids = data.sample(n=500, random_state=529).index\n",
    "\n",
    "    train = (\n",
    "        data.loc[~data.index.isin(holdout_ids)]\n",
    "        .sample(frac=1, random_state=529)\n",
    "        .sort_values(\"doctor\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    holdout = (\n",
    "        data.loc[data.index.isin(holdout_ids)]\n",
    "        .sample(frac=1, random_state=529)\n",
    "        .sort_values(\"doctor\")\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    return train, holdout\n",
    "\n",
    "train, holdout = get_prep_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "994e9045-958e-4767-a0b8-fbff143ea968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "      <th>doctor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21852</td>\n",
       "      <td>Male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>children</td>\n",
       "      <td>Rural</td>\n",
       "      <td>96.47</td>\n",
       "      <td>19.5</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72861</td>\n",
       "      <td>Female</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>69.30</td>\n",
       "      <td>20.1</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13072</td>\n",
       "      <td>Female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Urban</td>\n",
       "      <td>70.87</td>\n",
       "      <td>22.1</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64597</td>\n",
       "      <td>Female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>73.20</td>\n",
       "      <td>28.9</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31692</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>83.16</td>\n",
       "      <td>28.3</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease  ever_married  \\\n",
       "0  21852    Male   2.0             0              0         False   \n",
       "1  72861  Female  52.0             0              0          True   \n",
       "2  13072  Female  35.0             0              0          True   \n",
       "3  64597  Female  33.0             0              0          True   \n",
       "4  31692    Male  67.0             0              0          True   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0       children          Rural              96.47  19.5          Unknown   \n",
       "1        Private          Urban              69.30  20.1     never smoked   \n",
       "2  Self-employed          Urban              70.87  22.1  formerly smoked   \n",
       "3        Private          Rural              73.20  28.9          Unknown   \n",
       "4        Private          Rural              83.16  28.3     never smoked   \n",
       "\n",
       "   stroke  doctor  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9dff24e0-7794-42f6-8070-453af6ac2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y(train):\n",
    "    FEATURES = [\n",
    "        \"gender\",\n",
    "        \"age\",\n",
    "        \"hypertension\",\n",
    "        \"heart_disease\",\n",
    "        \"ever_married\",\n",
    "        \"work_type\",\n",
    "        \"Residence_type\",\n",
    "        \"avg_glucose_level\",\n",
    "        \"bmi\",\n",
    "        \"smoking_status\",\n",
    "    ]\n",
    "\n",
    "    GROUPS = \"doctor\"\n",
    "\n",
    "    TARGET = \"stroke\"\n",
    "\n",
    "    X = train[FEATURES]\n",
    "    y = train[TARGET]\n",
    "    groups = train[GROUPS]\n",
    "    return X, y, groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc508b6b-c30c-4920-9d34-d0bd8a92c159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 223, number of negative: 4387\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 635\n",
      "[LightGBM] [Info] Number of data points in the train set: 4610, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048373 -> initscore=-2.979229\n",
      "[LightGBM] [Info] Start training from score -2.979229\n",
      "The score on the training set is accuracy: 0.9911 and AUC of 0.9997\n"
     ]
    }
   ],
   "source": [
    "X, y, groups = get_X_y(train)\n",
    "clf = lgb.LGBMClassifier(n_estimators=100)\n",
    "clf.fit(X, y)\n",
    "# Predict on training set\n",
    "pred = clf.predict(X)\n",
    "pred_prob = clf.predict_proba(X)[:, 1]\n",
    "\n",
    "acc_score = accuracy_score(y, pred)\n",
    "auc_score = roc_auc_score(y, pred_prob)\n",
    "\n",
    "print(f'The score on the training set is accuracy: {acc_score:0.4f} and AUC of {auc_score:0.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bf30145-f5ec-47fe-912c-9c7c5676f30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our accuracy on the holdout set is 0.9380 and AUC is 0.7802\n"
     ]
    }
   ],
   "source": [
    "X_holdout, y_holdout, groups_holdout = get_X_y(holdout)\n",
    "\n",
    "pred = clf.predict(X_holdout)\n",
    "pred_prob = clf.predict_proba(X_holdout)[:, 1]\n",
    "acc_score = accuracy_score(y_holdout, pred)\n",
    "auc_score = roc_auc_score(y_holdout, pred_prob)\n",
    "print(\n",
    "    f\"Our accuracy on the holdout set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8875c61b-dbcf-4f31-a77c-3751eace403a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our baseline on the holdout set is 0.9480 and AUC is 0.5000\n"
     ]
    }
   ],
   "source": [
    "acc_score = accuracy_score(y_holdout, np.zeros_like(y_holdout))\n",
    "auc_score = roc_auc_score(y_holdout, np.zeros_like(y_holdout))\n",
    "print(\n",
    "    f\"Our baseline on the holdout set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c423ea45-7ee7-4368-9add-7bd22f83eab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 206, number of negative: 3943\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 4149, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.049651 -> initscore=-2.951821\n",
      "[LightGBM] [Info] Start training from score -2.951821\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Our accuracy on the validation set is 0.9675 and AUC is 0.9086\n"
     ]
    }
   ],
   "source": [
    "X, y, groups = get_X_y(train)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=0.1)\n",
    "clf = lgb.LGBMClassifier(n_estimators=100, max_depth=3)\n",
    "clf.fit(X_tr, y_tr)\n",
    "pred = clf.predict(X_val)\n",
    "pred_prob = clf.predict_proba(X_val)[:, 1]\n",
    "acc_score = accuracy_score(y_val, pred)\n",
    "auc_score = roc_auc_score(y_val, pred_prob)\n",
    "print(\n",
    "    f\"Our accuracy on the validation set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f98dc142-1783-4437-9c8b-35ecda9b53fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 198, number of negative: 3861\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 4059, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048780 -> initscore=-2.970414\n",
      "[LightGBM] [Info] Start training from score -2.970414\n",
      "======= Fold 0 ========\n",
      "Our accuracy on the validation set is 0.9510 and AUC is 0.8262\n",
      "[LightGBM] [Info] Number of positive: 170, number of negative: 3304\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000232 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 633\n",
      "[LightGBM] [Info] Number of data points in the train set: 3474, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048935 -> initscore=-2.967091\n",
      "[LightGBM] [Info] Start training from score -2.967091\n",
      "======= Fold 1 ========\n",
      "Our accuracy on the validation set is 0.9410 and AUC is 0.7868\n",
      "[LightGBM] [Info] Number of positive: 195, number of negative: 3806\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 4001, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048738 -> initscore=-2.971334\n",
      "[LightGBM] [Info] Start training from score -2.971334\n",
      "======= Fold 2 ========\n",
      "Our accuracy on the validation set is 0.9524 and AUC is 0.8858\n",
      "[LightGBM] [Info] Number of positive: 159, number of negative: 3261\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 631\n",
      "[LightGBM] [Info] Number of data points in the train set: 3420, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.046491 -> initscore=-3.020885\n",
      "[LightGBM] [Info] Start training from score -3.020885\n",
      "======= Fold 3 ========\n",
      "Our accuracy on the validation set is 0.9437 and AUC is 0.8101\n",
      "[LightGBM] [Info] Number of positive: 170, number of negative: 3316\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 634\n",
      "[LightGBM] [Info] Number of data points in the train set: 3486, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.048766 -> initscore=-2.970716\n",
      "[LightGBM] [Info] Start training from score -2.970716\n",
      "======= Fold 4 ========\n",
      "Our accuracy on the validation set is 0.9493 and AUC is 0.8667\n",
      "Our out of fold AUC score is 0.8351\n"
     ]
    }
   ],
   "source": [
    "sgk = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=529)\n",
    "\n",
    "X, y, groups = get_X_y(train)\n",
    "\n",
    "fold = 0\n",
    "aucs = []\n",
    "for train_idx, val_idx in sgk.split(X, y, groups):\n",
    "    X_tr = X.loc[train_idx]\n",
    "    y_tr = y.loc[train_idx]\n",
    "    \n",
    "    X_val = X.loc[val_idx]\n",
    "    y_val = y.loc[val_idx]\n",
    "\n",
    "    # Fit Model on Train\n",
    "    clf = lgb.LGBMClassifier(n_estimators=100)\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    pred = clf.predict(X_val)\n",
    "    pred_prob = clf.predict_proba(X_val)[:, 1]\n",
    "    acc_score = accuracy_score(y_val, pred)\n",
    "    auc_score = roc_auc_score(y_val, pred_prob)\n",
    "    print(f\"======= Fold {fold} ========\")\n",
    "    print(\n",
    "        f\"Our accuracy on the validation set is {acc_score:0.4f} and AUC is {auc_score:0.4f}\"\n",
    "    )\n",
    "    fold += 1\n",
    "    aucs.append(auc_score)\n",
    "oof_auc = np.mean(aucs)\n",
    "print(f'Our out of fold AUC score is {oof_auc:0.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
